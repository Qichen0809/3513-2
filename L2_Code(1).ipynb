{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2: Python Code Examples\n",
    "\n",
    "This notebook contains all the Python code examples from the Beamer presentation `Lecture 2: Introduction to Python for Data Analytics`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Python Environment: IPython & Jupyter\n",
    "\n",
    "Data analysis is an interactive and exploratory process. IPython (Interactive Python) and Jupyter Notebooks are essential tools that provide an environment perfect for this kind of work, allowing you to mix executable code, text, equations, and visualisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introspection with `?`\n",
    "\n",
    "A powerful feature of IPython/Jupyter is **introspection**. By placing a question mark (`?`) after a function or object, you can pull up its documentation (known as a \"docstring\") and other helpful information. This is incredibly useful for understanding how a library function works without having to search online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mSignature:\u001b[39m\n",
      "pd.read_csv(\n",
      "    filepath_or_buffer: \u001b[33m'FilePath | ReadCsvBuffer[bytes] | ReadCsvBuffer[str]'\u001b[39m,\n",
      "    *,\n",
      "    sep: \u001b[33m'str | None | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    delimiter: \u001b[33m'str | None | lib.NoDefault'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    header: \u001b[33m\"int | Sequence[int] | None | Literal['infer']\"\u001b[39m = \u001b[33m'infer'\u001b[39m,\n",
      "    names: \u001b[33m'Sequence[Hashable] | None | lib.NoDefault'\u001b[39m = <no_default>,\n",
      "    index_col: \u001b[33m'IndexLabel | Literal[False] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    usecols: \u001b[33m'UsecolsArgType'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    dtype: \u001b[33m'DtypeArg | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    engine: \u001b[33m'CSVEngine | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    converters: \u001b[33m'Mapping[HashableT, Callable] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    true_values: \u001b[33m'list | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    false_values: \u001b[33m'list | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    skipinitialspace: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    skiprows: \u001b[33m'list[int] | int | Callable[[Hashable], bool] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    skipfooter: \u001b[33m'int'\u001b[39m = \u001b[32m0\u001b[39m,\n",
      "    nrows: \u001b[33m'int | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    na_values: \u001b[33m'Hashable | Iterable[Hashable] | Mapping[Hashable, Iterable[Hashable]] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    keep_default_na: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    na_filter: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    skip_blank_lines: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    parse_dates: \u001b[33m'bool | Sequence[Hashable] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    date_format: \u001b[33m'str | dict[Hashable, str] | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    dayfirst: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    cache_dates: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    iterator: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    chunksize: \u001b[33m'int | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    compression: \u001b[33m'CompressionOptions'\u001b[39m = \u001b[33m'infer'\u001b[39m,\n",
      "    thousands: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    decimal: \u001b[33m'str'\u001b[39m = \u001b[33m'.'\u001b[39m,\n",
      "    lineterminator: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    quotechar: \u001b[33m'str'\u001b[39m = \u001b[33m'\"'\u001b[39m,\n",
      "    quoting: \u001b[33m'int'\u001b[39m = \u001b[32m0\u001b[39m,\n",
      "    doublequote: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    escapechar: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    comment: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    encoding: \u001b[33m'str | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    encoding_errors: \u001b[33m'str | None'\u001b[39m = \u001b[33m'strict'\u001b[39m,\n",
      "    dialect: \u001b[33m'str | csv.Dialect | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    on_bad_lines: \u001b[33m'str'\u001b[39m = \u001b[33m'error'\u001b[39m,\n",
      "    low_memory: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n",
      "    memory_map: \u001b[33m'bool'\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "    float_precision: \u001b[33m\"Literal['high', 'legacy', 'round_trip'] | None\"\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    storage_options: \u001b[33m'StorageOptions | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "    dtype_backend: \u001b[33m'DtypeBackend | lib.NoDefault'\u001b[39m = <no_default>,\n",
      ") -> \u001b[33m'DataFrame | TextFileReader'\u001b[39m\n",
      "\u001b[31mDocstring:\u001b[39m\n",
      "Read a comma-separated values (csv) file into DataFrame.\n",
      "\n",
      "Also supports optionally iterating or breaking of the file\n",
      "into chunks.\n",
      "\n",
      "Additional help can be found in the online docs for\n",
      "`IO Tools <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html>`_.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "filepath_or_buffer : str, path object or file-like object\n",
      "    Any valid string path is acceptable. The string could be a URL. Valid\n",
      "    URL schemes include http, ftp, s3, gs, and file. For file URLs, a host is\n",
      "    expected. A local file could be: file://localhost/path/to/table.csv.\n",
      "\n",
      "    If you want to pass in a path object, pandas accepts any ``os.PathLike``.\n",
      "\n",
      "    By file-like object, we refer to objects with a ``read()`` method, such as\n",
      "    a file handle (e.g. via builtin ``open`` function) or ``StringIO``.\n",
      "sep : str, default ','\n",
      "    Character or regex pattern to treat as the delimiter. If ``sep=None``, the\n",
      "    C engine cannot automatically detect\n",
      "    the separator, but the Python parsing engine can, meaning the latter will\n",
      "    be used and automatically detect the separator from only the first valid\n",
      "    row of the file by Python's builtin sniffer tool, ``csv.Sniffer``.\n",
      "    In addition, separators longer than 1 character and different from\n",
      "    ``'\\s+'`` will be interpreted as regular expressions and will also force\n",
      "    the use of the Python parsing engine. Note that regex delimiters are prone\n",
      "    to ignoring quoted data. Regex example: ``'\\r\\t'``.\n",
      "delimiter : str, optional\n",
      "    Alias for ``sep``.\n",
      "header : int, Sequence of int, 'infer' or None, default 'infer'\n",
      "    Row number(s) containing column labels and marking the start of the\n",
      "    data (zero-indexed). Default behavior is to infer the column names:\n",
      "    if no ``names``\n",
      "    are passed the behavior is identical to ``header=0`` and column\n",
      "    names are inferred from the first line of the file, if column\n",
      "    names are passed explicitly to ``names`` then the behavior is identical to\n",
      "    ``header=None``. Explicitly pass ``header=0`` to be able to\n",
      "    replace existing names. The header can be a list of integers that\n",
      "    specify row locations for a :class:`~pandas.MultiIndex` on the columns\n",
      "    e.g. ``[0, 1, 3]``. Intervening rows that are not specified will be\n",
      "    skipped (e.g. 2 in this example is skipped). Note that this\n",
      "    parameter ignores commented lines and empty lines if\n",
      "    ``skip_blank_lines=True``, so ``header=0`` denotes the first line of\n",
      "    data rather than the first line of the file.\n",
      "\n",
      "    When inferred from the file contents, headers are kept distinct from\n",
      "    each other by renaming duplicate names with a numeric suffix of the form\n",
      "    ``\".{{count}}\"`` starting from 1, e.g. ``\"foo\"`` and ``\"foo.1\"``.\n",
      "    Empty headers are named ``\"Unnamed: {{i}}\"`` or ``\n",
      "    \"Unnamed: {{i}}_level_{{level}}\"``\n",
      "    in the case of MultiIndex columns.\n",
      "names : Sequence of Hashable, optional\n",
      "    Sequence of column labels to apply. If the file contains a header row,\n",
      "    then you should explicitly pass ``header=0`` to override the column names.\n",
      "    Duplicates in this list are not allowed.\n",
      "index_col : Hashable, Sequence of Hashable or False, optional\n",
      "    Column(s) to use as row label(s), denoted either by column labels or column\n",
      "    indices.  If a sequence of labels or indices is given,\n",
      "    :class:`~pandas.MultiIndex`\n",
      "    will be formed for the row labels.\n",
      "\n",
      "    Note: ``index_col=False`` can be used to force pandas to *not* use the first\n",
      "    column as the index, e.g., when you have a malformed file with delimiters at\n",
      "    the end of each line.\n",
      "usecols : Sequence of Hashable or Callable, optional\n",
      "    Subset of columns to select, denoted either\n",
      "    by column labels or column indices.\n",
      "    If list-like, all elements must either\n",
      "    be positional (i.e. integer indices into the document columns) or strings\n",
      "    that correspond to column names provided either by the user in ``names`` or\n",
      "    inferred from the document header row(s).\n",
      "    If ``names`` are given, the document\n",
      "    header row(s) are not taken into account. For example, a valid list-like\n",
      "    ``usecols`` parameter would be ``[0, 1, 2]`` or ``['foo', 'bar', 'baz']``.\n",
      "    Element order is ignored, so ``usecols=[0, 1]`` is the same as ``[1, 0]``.\n",
      "    To instantiate a :class:`~pandas.DataFrame` from ``data`` with element order\n",
      "    preserved use ``pd.read_csv(data, usecols=['foo', 'bar'])[['foo', 'bar']]``\n",
      "    for columns in ``['foo', 'bar']`` order or\n",
      "    ``pd.read_csv(data, usecols=['foo', 'bar'])[['bar', 'foo']]``\n",
      "    for ``['bar', 'foo']`` order.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the column\n",
      "    names, returning names where the callable function evaluates to ``True``. An\n",
      "    example of a valid callable argument would be ``lambda x: x.upper() in\n",
      "    ['AAA', 'BBB', 'DDD']``. Using this parameter results in much faster\n",
      "    parsing time and lower memory usage.\n",
      "dtype : dtype or dict of {{Hashable : dtype}}, optional\n",
      "    Data type(s) to apply to either the whole dataset or individual columns.\n",
      "    E.g., ``{{'a': np.float64, 'b': np.int32, 'c': 'Int64'}}``\n",
      "    Use ``str`` or ``object`` together with suitable ``na_values`` settings\n",
      "    to preserve and not interpret ``dtype``.\n",
      "    If ``converters`` are specified, they will be applied INSTEAD\n",
      "    of ``dtype`` conversion. Specify a ``defaultdict`` as input where\n",
      "    the default determines the ``dtype``\n",
      "    of the columns which are not explicitly\n",
      "    listed.\n",
      "engine : {{'c', 'python', 'pyarrow'}}, optional\n",
      "    Parser engine to use. The C and pyarrow engines are faster,\n",
      "    while the python engine\n",
      "    is currently more feature-complete. Multithreading\n",
      "    is currently only supported by\n",
      "    the pyarrow engine. Some features of the \"pyarrow\" engine\n",
      "    are unsupported or may not work correctly.\n",
      "converters : dict of {{Hashable : Callable}}, optional\n",
      "    Functions for converting values in specified columns. Keys can either\n",
      "    be column labels or column indices.\n",
      "true_values : list, optional\n",
      "    Values to consider as ``True`` in addition\n",
      "    to case-insensitive variants of 'True'.\n",
      "false_values : list, optional\n",
      "    Values to consider as ``False`` in addition to case-insensitive\n",
      "    variants of 'False'.\n",
      "skipinitialspace : bool, default False\n",
      "    Skip spaces after delimiter.\n",
      "skiprows : int, list of int or Callable, optional\n",
      "    Line numbers to skip (0-indexed) or number of lines to skip (``int``)\n",
      "    at the start of the file.\n",
      "\n",
      "    If callable, the callable function will be evaluated against the row\n",
      "    indices, returning ``True`` if the row should be skipped and ``False``\n",
      "    otherwise.\n",
      "    An example of a valid callable argument would be ``lambda x: x in [0, 2]``.\n",
      "skipfooter : int, default 0\n",
      "    Number of lines at bottom of file to skip (Unsupported with ``engine='c'``).\n",
      "nrows : int, optional\n",
      "    Number of rows of file to read. Useful for reading pieces of large files.\n",
      "    Refers to the number of data rows in the returned DataFrame, excluding:\n",
      "\n",
      "    * The header row containing column names.\n",
      "    * Rows before the header row, if ``header=1`` or larger.\n",
      "\n",
      "    Example usage:\n",
      "\n",
      "    * To read the first 999,999 (non-header) rows:\n",
      "      ``read_csv(..., nrows=999999)``\n",
      "\n",
      "    * To read rows 1,000,000 through 1,999,999:\n",
      "      ``read_csv(..., skiprows=1000000, nrows=999999)``\n",
      "\n",
      "na_values : Hashable, Iterable of Hashable or dict of {{Hashable : Iterable}},\n",
      "    optional\n",
      "    Additional strings to recognize as ``NA``/``NaN``. If ``dict``\n",
      "    passed, specific\n",
      "    per-column ``NA`` values.  By default the following values\n",
      "    are interpreted as\n",
      "    ``NaN``: empty string, \"NaN\", \"N/A\", \"NULL\", and other common\n",
      "    representations of missing data.\n",
      "keep_default_na : bool, default True\n",
      "    Whether or not to include the default ``NaN`` values when parsing the data.\n",
      "    Depending on whether ``na_values`` is passed in, the behavior is as follows:\n",
      "\n",
      "    * If ``keep_default_na`` is ``True``, and ``na_values``\n",
      "      are specified, ``na_values``\n",
      "      is appended to the default ``NaN`` values used for parsing.\n",
      "    * If ``keep_default_na`` is ``True``, and ``na_values`` are not specified, only\n",
      "      the default ``NaN`` values are used for parsing.\n",
      "    * If ``keep_default_na`` is ``False``, and ``na_values`` are specified, only\n",
      "      the ``NaN`` values specified ``na_values`` are used for parsing.\n",
      "    * If ``keep_default_na`` is ``False``, and ``na_values`` are not specified, no\n",
      "      strings will be parsed as ``NaN``.\n",
      "\n",
      "    Note that if ``na_filter`` is passed in as ``False``,\n",
      "    the ``keep_default_na`` and\n",
      "    ``na_values`` parameters will be ignored.\n",
      "na_filter : bool, default True\n",
      "    Detect missing value markers (empty strings and the value of ``na_values``). In\n",
      "    data without any ``NA`` values, passing ``na_filter=False`` can improve the\n",
      "    performance of reading a large file.\n",
      "skip_blank_lines : bool, default True\n",
      "    If ``True``, skip over blank lines rather than interpreting as ``NaN`` values.\n",
      "parse_dates : bool, None, list of Hashable, default None\n",
      "    The behavior is as follows:\n",
      "\n",
      "    * ``bool``. If ``True`` -> try parsing the index.\n",
      "    * ``None``. Behaves like ``True`` if ``date_format`` is specified.\n",
      "    * ``list`` of ``int`` or names.\n",
      "      e.g. If ``[1, 2, 3]`` -> try parsing columns 1, 2, 3\n",
      "      each as a separate date column.\n",
      "\n",
      "    If a column or index cannot be represented as an array of ``datetime``,\n",
      "    say because of an unparsable value or a mixture of timezones, the column\n",
      "    or index will be returned unaltered as an ``object`` data type. For\n",
      "    non-standard ``datetime`` parsing, use :func:`~pandas.to_datetime` after\n",
      "    :func:`~pandas.read_csv`.\n",
      "\n",
      "    Note: A fast-path exists for iso8601-formatted dates.\n",
      "date_format : str or dict of column -> format, optional\n",
      "    Format to use for parsing dates and/or times when\n",
      "    used in conjunction with ``parse_dates``.\n",
      "    The strftime to parse time, e.g. :const:`\"%d/%m/%Y\"`. See\n",
      "    `strftime documentation\n",
      "    <https://docs.python.org/3/library/datetime.html\n",
      "    #strftime-and-strptime-behavior>`_ for more information on choices, though\n",
      "    note that :const:`\"%f\"`` will parse all the way up to nanoseconds.\n",
      "    You can also pass:\n",
      "\n",
      "    - \"ISO8601\", to parse any `ISO8601 <https://en.wikipedia.org/wiki/ISO_8601>`_\n",
      "      time string (not necessarily in exactly the same format);\n",
      "    - \"mixed\", to infer the format for each element individually. This is risky,\n",
      "      and you should probably use it along with `dayfirst`.\n",
      "\n",
      "    .. versionadded:: 2.0.0\n",
      "dayfirst : bool, default False\n",
      "    DD/MM format dates, international and European format.\n",
      "cache_dates : bool, default True\n",
      "    If ``True``, use a cache of unique, converted dates to apply the ``datetime``\n",
      "    conversion. May produce significant speed-up when parsing duplicate\n",
      "    date strings, especially ones with timezone offsets.\n",
      "\n",
      "iterator : bool, default False\n",
      "    Return ``TextFileReader`` object for iteration or getting chunks with\n",
      "    ``get_chunk()``.\n",
      "chunksize : int, optional\n",
      "    Number of lines to read from the file per chunk. Passing a value will cause the\n",
      "    function to return a ``TextFileReader`` object for iteration.\n",
      "    See the `IO Tools docs\n",
      "    <https://pandas.pydata.org/pandas-docs/stable/io.html#io-chunking>`_\n",
      "    for more information on ``iterator`` and ``chunksize``.\n",
      "\n",
      "compression : str or dict, default 'infer'\n",
      "    For on-the-fly decompression of on-disk data.\n",
      "    If 'infer' and 'filepath_or_buffer' is\n",
      "    path-like, then detect compression from the following extensions: '.gz',\n",
      "    '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "    (otherwise no compression).\n",
      "    If using 'zip' or 'tar', the ZIP file must contain only\n",
      "    one data file to be read in.\n",
      "    Set to ``None`` for no decompression.\n",
      "    Can also be a dict with key ``'method'`` set\n",
      "    to one of {``'zip'``, ``'gzip'``, ``'bz2'``,\n",
      "    ``'zstd'``, ``'xz'``, ``'tar'``} and\n",
      "    other key-value pairs are forwarded to\n",
      "    ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "    ``bz2.BZ2File``, ``zstandard.ZstdDecompressor``, ``lzma.LZMAFile`` or\n",
      "    ``tarfile.TarFile``, respectively.\n",
      "    As an example, the following could be passed for\n",
      "    Zstandard decompression using a\n",
      "    custom compression dictionary:\n",
      "    ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "\n",
      "thousands : str (length 1), optional\n",
      "    Character acting as the thousands separator in numerical values.\n",
      "decimal : str (length 1), default '.'\n",
      "    Character to recognize as decimal point (e.g., use ',' for European data).\n",
      "lineterminator : str (length 1), optional\n",
      "    Character used to denote a line break. Only valid with C parser.\n",
      "quotechar : str (length 1), optional\n",
      "    Character used to denote the start and end of a quoted item. Quoted\n",
      "    items can include the ``delimiter`` and it will be ignored.\n",
      "quoting : {{0 or csv.QUOTE_MINIMAL, 1 or csv.QUOTE_ALL,\n",
      "    2 or csv.QUOTE_NONNUMERIC, 3 or csv.QUOTE_NONE}}, default csv.QUOTE_MINIMAL\n",
      "    Control field quoting behavior per ``csv.QUOTE_*`` constants. Default is\n",
      "    ``csv.QUOTE_MINIMAL`` (i.e., 0) which implies that\n",
      "    only fields containing special\n",
      "    characters are quoted (e.g., characters defined\n",
      "    in ``quotechar``, ``delimiter``,\n",
      "    or ``lineterminator``.\n",
      "doublequote : bool, default True\n",
      "    When ``quotechar`` is specified and ``quoting`` is not ``QUOTE_NONE``, indicate\n",
      "    whether or not to interpret two consecutive ``quotechar`` elements INSIDE a\n",
      "    field as a single ``quotechar`` element.\n",
      "escapechar : str (length 1), optional\n",
      "    Character used to escape other characters.\n",
      "comment : str (length 1), optional\n",
      "    Character indicating that the remainder of line should not be parsed.\n",
      "    If found at the beginning\n",
      "    of a line, the line will be ignored altogether. This parameter must be a\n",
      "    single character. Like empty lines (as long as ``skip_blank_lines=True``),\n",
      "    fully commented lines are ignored by the parameter ``header`` but not by\n",
      "    ``skiprows``. For example, if ``comment='#'``, parsing\n",
      "    ``#empty\\na,b,c\\n1,2,3`` with ``header=0`` will result in ``'a,b,c'`` being\n",
      "    treated as the header.\n",
      "encoding : str, optional, default 'utf-8'\n",
      "    Encoding to use for UTF when reading/writing (ex. ``'utf-8'``). `List of Python\n",
      "    standard encodings\n",
      "    <https://docs.python.org/3/library/codecs.html#standard-encodings>`_ .\n",
      "\n",
      "encoding_errors : str, optional, default 'strict'\n",
      "    How encoding errors are treated. `List of possible values\n",
      "    <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "\n",
      "dialect : str or csv.Dialect, optional\n",
      "    If provided, this parameter will override values (default or not) for the\n",
      "    following parameters: ``delimiter``, ``doublequote``, ``escapechar``,\n",
      "    ``skipinitialspace``, ``quotechar``, and ``quoting``. If it is necessary to\n",
      "    override values, a ``ParserWarning`` will be issued. See ``csv.Dialect``\n",
      "    documentation for more details.\n",
      "on_bad_lines : {{'error', 'warn', 'skip'}} or Callable, default 'error'\n",
      "    Specifies what to do upon encountering a bad line (a line with too many fields).\n",
      "    Allowed values are:\n",
      "\n",
      "    - ``'error'``, raise an Exception when a bad line is encountered.\n",
      "    - ``'warn'``, raise a warning when a bad line is\n",
      "      encountered and skip that line.\n",
      "    - ``'skip'``, skip bad lines without raising or warning when\n",
      "      they are encountered.\n",
      "    - Callable, function that will process a single bad line.\n",
      "        - With ``engine='python'``, function with signature\n",
      "          ``(bad_line: list[str]) -> list[str] | None``.\n",
      "          ``bad_line`` is a list of strings split by the ``sep``.\n",
      "          If the function returns ``None``, the bad line will be ignored.\n",
      "          If the function returns a new ``list`` of strings with\n",
      "          more elements than\n",
      "          expected, a ``ParserWarning`` will be emitted while\n",
      "          dropping extra elements.\n",
      "        - With ``engine='pyarrow'``, function with signature\n",
      "          as described in pyarrow documentation: `invalid_row_handler\n",
      "          <https://arrow.apache.org/docs/python\n",
      "          /generated/pyarrow.csv.ParseOptions.html\n",
      "          #pyarrow.csv.ParseOptions.invalid_row_handler>`_.\n",
      "\n",
      "    .. versionchanged:: 2.2.0\n",
      "\n",
      "        Callable for ``engine='pyarrow'``\n",
      "\n",
      "low_memory : bool, default True\n",
      "    Internally process the file in chunks, resulting in lower memory use\n",
      "    while parsing, but possibly mixed type inference.  To ensure no mixed\n",
      "    types either set ``False``, or specify the type with the ``dtype`` parameter.\n",
      "    Note that the entire file is read into a single :class:`~pandas.DataFrame`\n",
      "    regardless, use the ``chunksize`` or ``iterator``\n",
      "    parameter to return the data in\n",
      "    chunks. (Only valid with C parser).\n",
      "memory_map : bool, default False\n",
      "    If a filepath is provided for ``filepath_or_buffer``, map the file object\n",
      "    directly onto memory and access the data directly from there. Using this\n",
      "    option can improve performance because there is no longer any I/O overhead.\n",
      "float_precision : {{'high', 'legacy', 'round_trip'}}, optional\n",
      "    Specifies which converter the C engine should use for floating-point\n",
      "    values. The options are ``None`` or ``'high'`` for the ordinary converter,\n",
      "    ``'legacy'`` for the original lower precision pandas converter, and\n",
      "    ``'round_trip'`` for the round-trip converter.\n",
      "\n",
      "storage_options : dict, optional\n",
      "    Extra options that make sense for a particular storage connection, e.g.\n",
      "    host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "    are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "    URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "    forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "    details, and for more examples on storage options refer `here\n",
      "    <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "    highlight=storage_options#reading-writing-remote-files>`_.\n",
      "\n",
      "dtype_backend : {{'numpy_nullable', 'pyarrow'}}\n",
      "    Back-end data type applied to the resultant :class:`DataFrame`\n",
      "    (still experimental). If not specified, the default behavior\n",
      "    is to not use nullable data types. If specified, the behavior\n",
      "    is as follows:\n",
      "\n",
      "    * ``\"numpy_nullable\"``: returns nullable-dtype-backed :class:`DataFrame`\n",
      "    * ``\"pyarrow\"``: returns\n",
      "      pyarrow-backed nullable :class:`ArrowDtype` :class:`DataFrame`\n",
      "\n",
      "    .. versionadded:: 2.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame or TextFileReader\n",
      "    A comma-separated values (csv) file is returned as two-dimensional\n",
      "    data structure with labeled axes.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.to_csv : Write DataFrame to a comma-separated values (csv) file.\n",
      "read_table : Read general delimited file into DataFrame.\n",
      "read_fwf : Read a table of fixed-width formatted lines into DataFrame.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> pd.read_csv(\"data.csv\")  # doctest: +SKIP\n",
      "   Name  Value\n",
      "0   foo      1\n",
      "1   bar      2\n",
      "2  #baz      3\n",
      "\n",
      "Index and header can be specified via the `index_col` and `header` arguments.\n",
      "\n",
      ">>> pd.read_csv(\"data.csv\", header=None)  # doctest: +SKIP\n",
      "      0      1\n",
      "0  Name  Value\n",
      "1   foo      1\n",
      "2   bar      2\n",
      "3  #baz      3\n",
      "\n",
      ">>> pd.read_csv(\"data.csv\", index_col=\"Value\")  # doctest: +SKIP\n",
      "       Name\n",
      "Value\n",
      "1       foo\n",
      "2       bar\n",
      "3      #baz\n",
      "\n",
      "Column types are inferred but can be explicitly specified using the dtype argument.\n",
      "\n",
      ">>> pd.read_csv(\"data.csv\", dtype={{\"Value\": float}})  # doctest: +SKIP\n",
      "   Name  Value\n",
      "0   foo    1.0\n",
      "1   bar    2.0\n",
      "2  #baz    3.0\n",
      "\n",
      "True, False, and NA values, and thousands separators have defaults,\n",
      "but can be explicitly specified, too. Supply the values you would like\n",
      "as strings or lists of strings!\n",
      "\n",
      ">>> pd.read_csv(\"data.csv\", na_values=[\"foo\", \"bar\"])  # doctest: +SKIP\n",
      "   Name  Value\n",
      "0   NaN      1\n",
      "1   NaN      2\n",
      "2  #baz      3\n",
      "\n",
      "Comment lines in the input file can be skipped using the `comment` argument.\n",
      "\n",
      ">>> pd.read_csv(\"data.csv\", comment=\"#\")  # doctest: +SKIP\n",
      "  Name  Value\n",
      "0  foo      1\n",
      "1  bar      2\n",
      "\n",
      "By default, columns with dates will be read as ``object`` rather than  ``datetime``.\n",
      "\n",
      ">>> df = pd.read_csv(\"tmp.csv\")  # doctest: +SKIP\n",
      "\n",
      ">>> df  # doctest: +SKIP\n",
      "   col 1       col 2            col 3\n",
      "0     10  10/04/2018  Sun 15 Jan 2023\n",
      "1     20  15/04/2018  Fri 12 May 2023\n",
      "\n",
      ">>> df.dtypes  # doctest: +SKIP\n",
      "col 1     int64\n",
      "col 2    object\n",
      "col 3    object\n",
      "dtype: object\n",
      "\n",
      "Specific columns can be parsed as dates by using the `parse_dates` and\n",
      "`date_format` arguments.\n",
      "\n",
      ">>> df = pd.read_csv(\n",
      "...     \"tmp.csv\",\n",
      "...     parse_dates=[1, 2],\n",
      "...     date_format={{\"col 2\": \"%d/%m/%Y\", \"col 3\": \"%a %d %b %Y\"}},\n",
      "... )  # doctest: +SKIP\n",
      "\n",
      ">>> df.dtypes  # doctest: +SKIP\n",
      "col 1             int64\n",
      "col 2    datetime64[ns]\n",
      "col 3    datetime64[ns]\n",
      "dtype: object\n",
      "\u001b[31mFile:\u001b[39m      /opt/miniconda3/envs/datascience/lib/python3.11/site-packages/pandas/io/parsers/readers.py\n",
      "\u001b[31mType:\u001b[39m      function"
     ]
    }
   ],
   "source": [
    "# First, we need to import the pandas library to use its functions.\n",
    "# We use the standard alias 'pd' to make our code shorter and more readable.\n",
    "import pandas as pd\n",
    "\n",
    "# Now, let's use introspection to get help on the 'read_csv' function from pandas.\n",
    "# This command will open a help pane at the bottom of the screen in Jupyter.\n",
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic Commands\n",
    "\n",
    "Magic commands, which start with a `%` or `%%`, provide special functionalities within the IPython/Jupyter environment. They are not part of the Python language itself but are shortcuts for common tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `%timeit`: Measuring Performance\n",
    "\n",
    "The `%timeit` magic command is used to accurately measure the execution time of a small piece of code. It runs the code multiple times and provides a statistical average, giving a more reliable performance measure than a single run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 μs ± 424 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# We use %timeit to measure how long it takes to create a list of the first 1000 square numbers.\n",
    "# This is a list comprehension, a concise way to create lists.\n",
    "%timeit [x**2 for x in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Import Conventions\n",
    "\n",
    "In data science, we use standard aliases when importing common libraries. This practice makes code consistent and easily readable by others in the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import NumPy for numerical operations, aliased as np.\n",
    "import numpy as np\n",
    "\n",
    "# Import pandas for data manipulation, aliased as pd.\n",
    "import pandas as pd\n",
    "\n",
    "# Import Matplotlib's pyplot for plotting, aliased as plt.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The Path object from pathlib provides an object-oriented way to handle filesystem paths.\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Python Language Basics\n",
    "\n",
    "This section covers the fundamental syntax and semantics of the Python language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indentation and Function Definition\n",
    "\n",
    "Unlike languages that use braces `{}` to define code blocks, Python uses **indentation** (typically 4 spaces). A colon `:` signifies the start of an indented block. This enforces a clean and readable code style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'def' keyword starts a function definition.\n",
    "# 'add' is the function name, and (a, b) are its parameters.\n",
    "def add(a, b):\n",
    "    # This indented block is the body of the function.\n",
    "    # A '#' symbol denotes a comment, which is ignored by Python.\n",
    "    # This function returns the sum of the two input numbers.\n",
    "    return a + b\n",
    "\n",
    "# Call the function 'add' with arguments 5 and 3.\n",
    "result = add(5, 3)\n",
    "\n",
    "# An f-string (formatted string literal) lets us embed expressions inside string literals.\n",
    "# Here, we print the value of the 'result' variable.\n",
    "print(f\"The result is {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables as References\n",
    "\n",
    "When you assign a variable to another (e.g., `b = a`), you are not creating a copy of the object. Instead, you are creating a new label or **reference** that points to the *exact same object* in memory. If the object is mutable (like a list), changes made through one reference will be visible through the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'a' is a variable that refers to a list object in memory.\n",
    "a = [1, 2, 3]\n",
    "\n",
    "# 'b = a' does NOT copy the list. 'b' now points to the SAME list object as 'a'.\n",
    "b = a\n",
    "\n",
    "# We modify the list using the reference 'a'.\n",
    "a.append(4)\n",
    "\n",
    "# When we print 'b', we see the change because both variables point to the same list.\n",
    "print(b) # Output will be [1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Data Types\n",
    "These are the basic building blocks for data in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integers (`int`) and Floats (`float`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An integer is a whole number.\n",
    "my_integer = 100\n",
    "\n",
    "# Python's integers can be arbitrarily large.\n",
    "large_integer = 10**12 # This is 1 trillion.\n",
    "\n",
    "print(f\"My integer: {my_integer}\")\n",
    "print(f\"Large integer: {large_integer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A float is a number with a decimal point.\n",
    "my_float = 3.14159\n",
    "\n",
    "# Floats can also be written in scientific notation.\n",
    "scientific_notation = 6.78e-5 # This is equal to 0.0000678\n",
    "\n",
    "print(f\"My float: {my_float}\")\n",
    "print(f\"Scientific notation: {scientific_notation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arithmetic\n",
    "\n",
    "Pay attention to the difference between standard division (`/`), which always produces a float, and floor division (`//`), which discards the remainder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard division (/) always results in a float, even if the numbers divide evenly.\n",
    "result = 10 / 3\n",
    "print(f\"10 / 3 = {result}\")\n",
    "\n",
    "# Floor division (//) discards the fractional part and returns an integer.\n",
    "floor_result = 10 // 3\n",
    "print(f\"10 // 3 = {floor_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strings (`str`)\n",
    "\n",
    "Strings are used to store text data. They are **immutable**, meaning they cannot be changed after creation. String methods always return a *new* string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a string with leading and trailing whitespace.\n",
    "my_string = \"  Hello, World!  \"\n",
    "\n",
    "# The .strip() method removes whitespace from the beginning and end.\n",
    "print(my_string.strip()) \n",
    "\n",
    "# The .lower() method converts the entire string to lowercase.\n",
    "print(my_string.lower()) \n",
    "\n",
    "# The .replace() method returns a new string with specified phrases replaced.\n",
    "print(my_string.replace(\"World\", \"Python\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Booleans (`bool`) and `None`\n",
    "\n",
    "Booleans represent the truth values `True` and `False`. They are the result of comparison operations and are fundamental to control flow.\n",
    "\n",
    "`None` is a special type that represents the absence of a value. It's often used as a placeholder or to signal that a variable is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A comparison operator (>) results in a boolean value.\n",
    "is_greater = 10 > 5 # This evaluates to True.\n",
    "\n",
    "# The equality operator (==) checks if two values are equal.\n",
    "is_equal = 5 == 6   # This evaluates to False.\n",
    "\n",
    "# Boolean values can be combined with logical operators 'and', 'or', and 'not'.\n",
    "result = is_greater and not is_equal # True and not False -> True and True -> True\n",
    "\n",
    "print(f\"is_greater is: {is_greater}\")\n",
    "print(f\"is_equal is: {is_equal}\")\n",
    "print(f\"The final result is: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'None' is used to represent an empty or null value.\n",
    "my_variable = None\n",
    "\n",
    "# Use 'is None' to check if a variable has the value None.\n",
    "if my_variable is None:\n",
    "    print(\"The variable has no value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dates and Times (`datetime`)\n",
    "\n",
    "Python's built-in `datetime` module is the standard way to handle dates and times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the specific classes 'datetime' and 'timedelta' from the 'datetime' module.\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Get the current date and time.\n",
    "now = datetime.now()\n",
    "\n",
    "# A 'timedelta' represents a duration of time.\n",
    "# Here, we subtract 14 days from the current moment.\n",
    "two_weeks_ago = now - timedelta(days=14)\n",
    "\n",
    "# The strftime method formats a datetime object into a string.\n",
    "# '%Y' is the full year, '%m' is the month, and '%d' is the day.\n",
    "print(f\"The current datetime is: {now}\")\n",
    "print(f\"Two weeks ago was: {two_weeks_ago}\")\n",
    "print(f\"Formatted date for two weeks ago: {two_weeks_ago.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type Casting\n",
    "\n",
    "You can explicitly convert values from one type to another using functions like `int()`, `float()`, `str()`, and `bool()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a string that looks like a number.\n",
    "s = '3.14159'\n",
    "\n",
    "# Convert the string 's' to a floating-point number.\n",
    "fval = float(s)\n",
    "# The type() function confirms the new type of the variable.\n",
    "print(f\"fval is {fval} and its type is {type(fval)}\")\n",
    "\n",
    "# Convert the float 'fval' to an integer. This truncates (cuts off) the decimal part.\n",
    "ival = int(fval)\n",
    "print(f\"ival is {ival} and its type is {type(ival)}\")\n",
    "\n",
    "# Convert the integer to a boolean. Any non-zero number is True.\n",
    "print(f\"The boolean value of {ival} is {bool(ival)}\")\n",
    "\n",
    "# Converting 0 to a boolean results in False.\n",
    "print(f\"The boolean value of 0 is {bool(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Built-in Data Structures\n",
    "\n",
    "Python comes with several powerful and flexible data structures for organising collections of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuples\n",
    "\n",
    "A tuple is a fixed-length, **immutable** sequence of Python objects. Once a tuple is created, its contents cannot be changed. They are often used for data that should not be modified, such as the components of a coordinate or a key in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tuple is created with parentheses ().\n",
    "tup = (4, 5, 6)\n",
    "# trying to change an element like `tup[1] = 0` would cause a TypeError.\n",
    "\n",
    "# Unpacking a tuple assigns its elements to variables.\n",
    "# The number of variables must match the number of elements in the tuple.\n",
    "a, b, c = tup\n",
    "print(f\"Unpacked variable 'a' is: {a}\")\n",
    "\n",
    "# Tuples have a .count() method to count occurrences of a value.\n",
    "another_tuple = (1, 2, 2, 2, 3)\n",
    "print(f\"The number 2 appears {another_tuple.count(2)} times.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists\n",
    "\n",
    "A list is a variable-length, **mutable** sequence. It is the most common and versatile sequence type in Python. You can add, remove, and change elements after the list has been created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding and Removing Elements from a List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list is created with square brackets [].\n",
    "a_list = [2, 3, 7]\n",
    "print(f\"Initial list: {a_list}\")\n",
    "\n",
    "# .append() adds an element to the end of the list.\n",
    "a_list.append(9)\n",
    "print(f\"After append(9): {a_list}\")\n",
    "\n",
    "# .insert(index, value) adds an element at a specific position.\n",
    "a_list.insert(1, 5)\n",
    "print(f\"After insert(1, 5): {a_list}\")\n",
    "\n",
    "# .pop(index) removes and returns the element at a specific position.\n",
    "popped_value = a_list.pop(2)\n",
    "print(f\"Popped value at index 2 was: {popped_value}\")\n",
    "print(f\"List after pop(2): {a_list}\")\n",
    "\n",
    "# .remove(value) removes the first occurrence of a specific value.\n",
    "a_list.remove(9)\n",
    "print(f\"List after remove(9): {a_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining and Sorting Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two lists.\n",
    "x = [1, 2, 3]\n",
    "y = [4, 5]\n",
    "\n",
    "# Using the '+' operator creates a new list without modifying the originals.\n",
    "concatenated_list = x + y\n",
    "print(f\"Result of x + y: {concatenated_list}\")\n",
    "print(f\"Original x is still: {x}\") # x is unchanged\n",
    "\n",
    "# The .extend() method modifies the list in-place by appending elements from another sequence.\n",
    "x.extend(y)\n",
    "print(f\"Result of x.extend(y): {x}\") # x is now changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an unsorted list.\n",
    "a = [7, 2, 5, 1, 3]\n",
    "print(f\"Unsorted list: {a}\")\n",
    "\n",
    "# The .sort() method sorts the list in-place (it modifies the original list).\n",
    "a.sort()\n",
    "print(f\"Sorted list: {a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Slicing Lists\n",
    "\n",
    "Slicing is a powerful feature that lets you select sub-lists using the syntax `start:stop:step`. The `start` index is included, but the `stop` index is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequence to slice.\n",
    "seq = [7, 2, 3, 7, 5, 6, 0, 1]\n",
    "\n",
    "# Slice from index 1 up to (but not including) index 5.\n",
    "print(f\"Slice [1:5]: {seq[1:5]}\")\n",
    "\n",
    "# Omitting the start index defaults to the beginning of the list.\n",
    "print(f\"First 5 elements: {seq[:5]}\")\n",
    "\n",
    "# Negative indices count from the end of the list.\n",
    "print(f\"Last 4 elements: {seq[-4:]}\")\n",
    "\n",
    "# The 'step' argument allows you to skip elements. Here we take every second element.\n",
    "print(f\"Every other element: {seq[::2]}\")\n",
    "\n",
    "# A step of -1 reverses the list.\n",
    "print(f\"Reversed: {seq[::-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries (`dict`)\n",
    "\n",
    "A dictionary stores a collection of key-value pairs. They are highly optimised for retrieving a value when you know the key. Keys must be immutable (e.g., strings, numbers, or tuples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary is created with curly braces {} and key: value pairs.\n",
    "d1 = {'a': 'some value', 'b': [1, 2, 3]}\n",
    "\n",
    "# Access the value associated with a key using square brackets.\n",
    "print(f\"The value for key 'b' is: {d1['b']}\")\n",
    "\n",
    "# Add a new key-value pair.\n",
    "d1['c'] = 'new value'\n",
    "print(f\"The dictionary after adding key 'c': {d1}\")\n",
    "\n",
    "# Check if a key exists in the dictionary using the 'in' keyword.\n",
    "print(f\"Is 'b' a key in d1? {'b' in d1}\")\n",
    "\n",
    "# The .keys() method returns a view of all keys.\n",
    "print(f\"All keys: {list(d1.keys())}\")\n",
    "\n",
    "# The .values() method returns a view of all values.\n",
    "print(f\"All values: {list(d1.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets\n",
    "\n",
    "A set is an unordered collection of **unique** elements. They are very fast for membership testing (checking if an element is present) and for performing mathematical set operations like union, intersection, and difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A set is created with curly braces {} or the set() function.\n",
    "# Duplicate elements are automatically removed.\n",
    "a = {1, 2, 3, 4, 5}\n",
    "b = {3, 4, 5, 6, 7, 8}\n",
    "\n",
    "# The union (|) contains all elements that are in either set.\n",
    "print(f\"Union (a | b): {a | b}\")\n",
    "\n",
    "# The intersection (&) contains only the elements that are in both sets.\n",
    "print(f\"Intersection (a & b): {a & b}\")\n",
    "\n",
    "# The difference (-) contains elements that are in set 'a' but not in set 'b'.\n",
    "print(f\"Difference (a - b): {a - b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehensions\n",
    "\n",
    "Comprehensions are a concise and readable way to create collections (lists, sets, dictionaries) in Python. They are often a more efficient and \"Pythonic\" alternative to a standard `for` loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `for` loop way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The comprehension way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the list of words.\n",
    "words = ['apple', 'bat', 'bar', 'atom']\n",
    "\n",
    "# This single line does the exact same thing as the for loop above.\n",
    "# [expression for item in list if condition]\n",
    "upper_words_comp = [x.upper() for x in words if x.startswith('a')]\n",
    "\n",
    "print(f\"Result from comprehension: {upper_words_comp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of words.\n",
    "words = ['apple', 'bat', 'bar', 'atom']\n",
    "# Create an empty list to store the results.\n",
    "upper_words = []\n",
    "# Loop through each word in the list.\n",
    "for x in words:\n",
    "    # Check if the word starts with 'a'.\n",
    "    if x.startswith('a'):\n",
    "        # If it does, convert it to uppercase and add it to the results list.\n",
    "        upper_words.append(x.upper())\n",
    "\n",
    "print(f\"Result from for loop: {upper_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control Flow\n",
    "\n",
    "Control flow statements allow you to direct the execution of your code based on certain conditions or to repeat blocks of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `for` Loops\n",
    "\n",
    "A `for` loop is used for **definite iteration**—that is, iterating over a sequence (like a list) where you know how many items there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise an empty list to store the results of our processing.\n",
    "processed = []\n",
    "# Define the list that we will iterate over.\n",
    "my_list = [1, 2, None, 4]\n",
    "\n",
    "# The 'for' loop will assign each item from 'my_list' to the variable 'val' one by one.\n",
    "for val in my_list:\n",
    "    # Check if the current value ('val') is None.\n",
    "    if val is None:\n",
    "        # The 'continue' keyword immediately stops the current iteration and jumps to the next one.\n",
    "        continue\n",
    "    # If the value is not None, we double it and append it to our 'processed' list.\n",
    "    processed.append(val * 2)\n",
    "\n",
    "print(f\"The original list was: {my_list}\")\n",
    "print(f\"The processed list is: {processed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `while` Loops\n",
    "\n",
    "A `while` loop is used for **indefinite iteration**. The loop continues to run as long as a specified condition is `True`. You must ensure the condition eventually becomes `False`, or you will have an infinite loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the variable 'x' to 100.\n",
    "x = 100\n",
    "\n",
    "# This loop will continue as long as 'x' is greater than 0.\n",
    "while x > 0:\n",
    "    # Print the current value of x in each iteration.\n",
    "    print(f\"x is currently {x}\")\n",
    "    # Decrease x by 10. This is crucial to ensure the loop eventually ends.\n",
    "    x = x - 10\n",
    "    # Check if x has dropped below 50.\n",
    "    if x < 50:\n",
    "        # The 'break' keyword exits the loop immediately, regardless of the 'while' condition.\n",
    "        print(\"x is less than 50, breaking the loop!\")\n",
    "        break\n",
    "\n",
    "print(f\"The loop finished with x = {x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditionals (`if`, `elif`, `else`)\n",
    "\n",
    "These statements allow you to execute different blocks of code based on a series of checks. Python evaluates them in order and runs the code block for the *first* condition that is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign an initial value to x.\n",
    "x = 10 \n",
    "\n",
    "# The 'if' statement checks the first condition.\n",
    "if x < 0:\n",
    "    status = \"negative\"\n",
    "# If the first condition was false, the 'elif' (else if) checks the next condition.\n",
    "elif x == 0:\n",
    "    status = \"zero\"\n",
    "# If none of the preceding conditions were true, the 'else' block is executed as a default.\n",
    "else:\n",
    "    status = \"positive\"\n",
    "\n",
    "# Display the resulting status.\n",
    "print(f\"The number {x} is {status}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `range`\n",
    "\n",
    "The `range` function generates a sequence of integers. It is very efficient as it doesn't store all the numbers in memory at once. It is commonly used with `for` loops to repeat an action a specific number of times. To see the numbers, you can convert the range object to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# range(5) generates integers from 0 up to (but not including) 5.\n",
    "print(f\"range(5): {list(range(5))}\") # -> [0, 1, 2, 3, 4]\n",
    "\n",
    "# range(0, 10, 2) generates integers starting at 0, up to 10, in steps of 2.\n",
    "print(f\"range(0, 10, 2): {list(range(0, 10, 2))}\") # -> [0, 2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Functions and Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "Functions are the primary way to organise code into logical, reusable blocks. They help make your code more modular, readable, and easier to debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function is a block of reusable code. We define one\n",
    "# called `clean_up_text` that takes one argument, `text`.\n",
    "def clean_up_text(text):\n",
    "    \n",
    "    # Use the .strip() method to remove any whitespace\n",
    "    # from the beginning and end of the text.\n",
    "    text_stripped = text.strip()\n",
    "\n",
    "    # Use the .lower() method to convert the entire\n",
    "    # string to lowercase letters.\n",
    "    text_lower = text_stripped.lower()\n",
    "\n",
    "    # Use the .replace() method to find all '!' characters\n",
    "    # and replace them with nothing (which removes them).\n",
    "    text_no_punct = text_lower.replace('!', '')\n",
    "\n",
    "    # The 'return' keyword sends the final, cleaned version of the text\n",
    "    # back as the function's output.\n",
    "    return text_no_punct\n",
    "\n",
    "\n",
    "# Let's define a string to test our function.\n",
    "original_string = \"   Hello World!   \"\n",
    "\n",
    "# Call the function with our string and store the returned result.\n",
    "cleaned_string = clean_up_text(original_string)\n",
    "\n",
    "\n",
    "# Print both versions to see the result of the cleaning.\n",
    "print(f\"Original: '{original_string}'\")\n",
    "print(f\"Cleaned: '{cleaned_string}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Function Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returning Multiple Values\n",
    "\n",
    "A function can return multiple values. Python automatically packs them into a tuple, which can then be conveniently unpacked into separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns three values.\n",
    "def f():\n",
    "    return 1, 2, 3\n",
    "\n",
    "# Call the function and unpack the returned tuple into three variables.\n",
    "a, b, c = f()\n",
    "print(f\"a={a}, b={b}, c={c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda (Anonymous) Functions\n",
    "\n",
    "For simple, one-line functions, you can use the `lambda` keyword to create a small, anonymous function. This is often used when you need to pass a simple function as an argument to another function, like the `key` argument in `sort()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of strings.\n",
    "words = ['banana', 'apple', 'fig']\n",
    "print(f\"Original list: {words}\")\n",
    "\n",
    "# Sort the list using the 'key' argument.\n",
    "# The lambda function `lambda x: x[-1]` takes an element `x` \n",
    "# and returns its last character `x[-1]`. \n",
    "# The list is then sorted based on these last characters ('a', 'e', 'g').\n",
    "words.sort(key=lambda x: x[-1])\n",
    "\n",
    "print(f\"List sorted by last letter: {words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generators\n",
    "\n",
    "A generator is a special kind of iterator, created by a function that uses the `yield` keyword. Instead of computing all values at once and storing them in memory, a generator produces values one at a time, on-the-fly. This is highly memory-efficient for working with very large sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is a generator because it uses 'yield'.\n",
    "def squares(n=5):\n",
    "    print(\"Generator started!\")\n",
    "    # Loop from 1 to n (inclusive).\n",
    "    for i in range(1, n + 1):\n",
    "        # 'yield' pauses the function, returns the value, and waits for the next call.\n",
    "        print(f\"Yielding {i**2}...\")\n",
    "        yield i ** 2\n",
    "\n",
    "# When we loop over the generator, the code inside 'squares' only runs when a value is requested.\n",
    "for val in squares():\n",
    "    print(f\"Received {val} from generator.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Handling\n",
    "\n",
    "Robust code should be able to handle potential errors gracefully without crashing. The `try...except` block is used for this. Code that might cause an error is placed in the `try` block, and the code to run if that specific error occurs is placed in the `except` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'try' block contains code that might fail.\n",
    "try:\n",
    "    # This line will cause a ZeroDivisionError.\n",
    "    result = 10 / 0\n",
    "# If a ZeroDivisionError occurs in the try block, the code in this 'except' block is executed.\n",
    "except ZeroDivisionError:\n",
    "    # Instead of crashing, the program will print this message.\n",
    "    print(\"Error: Cannot divide by zero!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Writing Files\n",
    "\n",
    "The standard and safest way to work with files is using the `with open(...)` statement. This ensures that the file is automatically closed when you are finished with it, even if errors occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing to a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'open' is used with the filename and a mode ('w' for write).\n",
    "# The 'with' statement handles opening and closing the file.\n",
    "with open('output.txt', 'w') as f:\n",
    "    # The .write() method writes a string to the file.\n",
    "    # '\\n' is the newline character to move to the next line.\n",
    "    f.write('Line 1\\n')\n",
    "    f.write('Line 2\\n')\n",
    "\n",
    "print(\"File 'output.txt' has been written successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading from a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to hold the lines from the file.\n",
    "lines = []\n",
    "# Open the file we just created in read mode ('r').\n",
    "with open('output.txt', 'r') as f:\n",
    "    # We can iterate directly over the file object 'f' to read it line by line.\n",
    "    for line in f:\n",
    "        # .strip() is used to remove the trailing newline character ('\\n') from each line.\n",
    "        lines.append(line.strip())\n",
    "\n",
    "print(f\"The lines read from the file are: {lines}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
